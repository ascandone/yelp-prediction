{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp photo-based star prediction â€” validation plots\n",
    "\n",
    "This notebook reproduces what `plot_predictions.py` does, but shows outputs inline.\n",
    "\n",
    "It assumes:\n",
    "- `data/features/features.pt` exists\n",
    "- `best_mil_model.pth` exists\n",
    "- dataset JSON + photos are under `data/` as per `dataframes.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT = c:\\Users\\matia\\OneDrive\\Desktop\\Data Science Master\\2.- FIRST SEMESTER\\DATA SCIENCE\\yelp-prediction\n",
      "SRC  = c:\\Users\\matia\\OneDrive\\Desktop\\Data Science Master\\2.- FIRST SEMESTER\\DATA SCIENCE\\yelp-prediction\\src\n"
     ]
    }
   ],
   "source": [
    "# Notebook bootstrap:\n",
    "# - Make imports work without `pip install -e .`\n",
    "# - Make relative paths (e.g., data/...) resolve correctly by forcing CWD to the repo root\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "\n",
    "# Walk up a few levels until we find the project root (contains `src/`)\n",
    "for _ in range(5):\n",
    "    if (ROOT / \"src\").exists():\n",
    "        break\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "SRC = ROOT / \"src\"\n",
    "if not SRC.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not locate project `src/` directory. Started from: {Path.cwd()} (resolved ROOT={ROOT})\"\n",
    "    )\n",
    "\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "# Force working directory to project root so that `data/...` paths work\n",
    "os.chdir(ROOT)\n",
    "\n",
    "print(\"CWD =\", Path.cwd())\n",
    "print(\"SRC =\", SRC)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from yelp_prediction import eval_utils as E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FEATURES_PATH = Path(\"data/features/features.pt\")\n",
    "MODEL_PATH = Path(\"best_mil_model.pth\")\n",
    "OUTDIR = Path(\"reports/figures_notebook\")\n",
    "MAX_PHOTOS = 3\n",
    "BATCH_SIZE = 256\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "El sistema no puede encontrar la ruta especificada. (os error 3): data\\dataset-json\\yelp_academic_dataset_business.json\n\nThis error occurred with the following context stack:\n\t[1] 'ndjson scan'\n\t[2] 'filter'\n\t[3] 'join left'\n\t[4] 'join'\n\t[5] 'join left'\n\t[6] 'join'\n\t[7] 'select'\n\t[8] 'with_columns'\n\t[9] 'sink'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load validation set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mE\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_features_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m _, val_df = E.make_train_val_split(df, seed=SEED, train_frac=\u001b[32m0.8\u001b[39m)\n\u001b[32m      5\u001b[39m median = E.compute_median_stars(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Desktop\\Data Science Master\\2.- FIRST SEMESTER\\DATA SCIENCE\\yelp-prediction\\src\\yelp_prediction\\eval_utils.py:57\u001b[39m, in \u001b[36mload_features_df\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_features_df\u001b[39m():\n\u001b[32m     54\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m    Loads the \"feature rows\" LazyFrame from `dataframes.q_features` and materializes it.\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataframes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mq_features\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Desktop\\Data Science Master\\2.- FIRST SEMESTER\\DATA SCIENCE\\yelp-prediction\\.venv\\Lib\\site-packages\\polars\\_utils\\deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Desktop\\Data Science Master\\2.- FIRST SEMESTER\\DATA SCIENCE\\yelp-prediction\\.venv\\Lib\\site-packages\\polars\\lazyframe\\opt_flags.py:328\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    327\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Desktop\\Data Science Master\\2.- FIRST SEMESTER\\DATA SCIENCE\\yelp-prediction\\.venv\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2429\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2427\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2428\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: El sistema no puede encontrar la ruta especificada. (os error 3): data\\dataset-json\\yelp_academic_dataset_business.json\n\nThis error occurred with the following context stack:\n\t[1] 'ndjson scan'\n\t[2] 'filter'\n\t[3] 'join left'\n\t[4] 'join'\n\t[5] 'join left'\n\t[6] 'join'\n\t[7] 'select'\n\t[8] 'with_columns'\n\t[9] 'sink'\n"
     ]
    }
   ],
   "source": [
    "# Load validation set\n",
    "df = E.load_features_df()\n",
    "_, val_df = E.make_train_val_split(df, seed=SEED, train_frac=0.8)\n",
    "\n",
    "median = E.compute_median_stars(df)\n",
    "features_dict = E.load_features_dict(FEATURES_PATH)\n",
    "model = E.load_model(MODEL_PATH, median_stars=median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference\n",
    "\n",
    "For notebook diagnostics, you can switch `sampling` to `deterministic` to remove randomness from photo selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = E.predict_val(\n",
    "    val_df,\n",
    "    features_dict=features_dict,\n",
    "    model=model,\n",
    "    max_photos=MAX_PHOTOS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    sampling=\"random\",  # or \"deterministic\"\n",
    ")\n",
    "\n",
    "mae, rmse = E.compute_metrics(payload[\"y_true\"], payload[\"y_pred\"])\n",
    "mae, rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter: true vs predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = payload[\"y_true\"]\n",
    "y_pred = payload[\"y_pred\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_true, y_pred, s=8, alpha=0.5)\n",
    "plt.plot([1, 5], [1, 5])\n",
    "plt.xlim(1, 5)\n",
    "plt.ylim(1, 5)\n",
    "plt.xlabel(\"True stars\")\n",
    "plt.ylabel(\"Predicted stars\")\n",
    "plt.title(f\"True vs Predicted (val) | MAE={mae:.3f}, RMSE={rmse:.3f}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter colored by available photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_avail = payload[\"n_available\"]\n",
    "\n",
    "plt.figure()\n",
    "sc = plt.scatter(y_true, y_pred, c=np.clip(n_avail, 1, None), s=8, alpha=0.5, norm=plt.matplotlib.colors.LogNorm())\n",
    "plt.colorbar(sc).set_label(\"Available photos (log scale)\")\n",
    "plt.plot([1, 5], [1, 5])\n",
    "plt.xlim(1, 5)\n",
    "plt.ylim(1, 5)\n",
    "plt.xlabel(\"True stars\")\n",
    "plt.ylabel(\"Predicted stars\")\n",
    "plt.title(\"True vs Predicted colored by #photos\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = y_pred - y_true\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(err, bins=50)\n",
    "plt.xlabel(\"Prediction error (y_pred - y_true)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Error distribution (val)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple binned calibration view (bin true stars to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.round(y_true * 2) / 2.0\n",
    "uniq = np.unique(bins)\n",
    "means = np.array([float(np.mean(y_pred[bins == u])) for u in uniq])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(uniq, means, marker=\"o\")\n",
    "plt.plot([1, 5], [1, 5])\n",
    "plt.xlabel(\"True stars (binned to 0.5)\")\n",
    "plt.ylabel(\"Avg predicted stars\")\n",
    "plt.title(\"Binned calibration (val)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the same artifacts as the script (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CSV\n",
    "E.save_predictions_csv(OUTDIR / \"val_predictions.csv\", payload=payload)\n",
    "\n",
    "# PNGs (same as script output naming)\n",
    "E.generate_all_plots(OUTDIR, payload=payload, mae=mae, rmse=rmse)\n",
    "\n",
    "OUTDIR.resolve()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}