{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Dataset coverage & bias diagnostics\n\nThis notebook reproduces `diagnose_bias.py` and shows tables/plots inline.\n\nIt focuses on whether the model is trained/evaluated on a photo-biased sample.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook bootstrap:\n",
    "# - Make imports work without `pip install -e .`\n",
    "# - Make relative paths (e.g., data/...) resolve correctly by forcing CWD to the repo root\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "\n",
    "# Walk up a few levels until we find the project root (contains `src/`)\n",
    "for _ in range(5):\n",
    "    if (ROOT / \"src\").exists():\n",
    "        break\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "SRC = ROOT / \"src\"\n",
    "if not SRC.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not locate project `src/` directory. Started from: {Path.cwd()} (resolved ROOT={ROOT})\"\n",
    "    )\n",
    "\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "# Force working directory to project root so that `data/...` paths work\n",
    "os.chdir(ROOT)\n",
    "\n",
    "print(\"CWD =\", Path.cwd())\n",
    "print(\"SRC =\", SRC)\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from yelp_prediction import bias_utils as B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "OUTDIR = Path(\"reports/diagnostics_notebook\")\nOUTDIR.mkdir(parents=True, exist_ok=True)\n\nPRED_CSV = Path(\"reports/figures/val_predictions.csv\")  # produced by plot_predictions\nLOW_THR = 3.0\nRESTAURANTS_ONLY = True\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Build the business-level coverage table"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = B.build_coverage_df(restaurants_only=RESTAURANTS_ONLY, low_thr=LOW_THR)\ndf.shape, df.head()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Coverage summary (same metrics as the script)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Reuse the existing writer, but also display the content\nsummary_path = OUTDIR / \"coverage_summary.txt\"\nB.write_coverage_summary(summary_path, df, restaurants_only=RESTAURANTS_ONLY, low_thr=LOW_THR)\nprint(summary_path.read_text(encoding=\"utf-8\"))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Stars distribution: all vs with photos vs without photos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "stars_all = df[\"stars_target\"].to_numpy()\nstars_with = df.filter(pl.col(\"has_photos\"))[\"stars_target\"].to_numpy()\nstars_without = df.filter(~pl.col(\"has_photos\"))[\"stars_target\"].to_numpy()\n\nplt.figure()\nplt.hist(stars_all, bins=40, alpha=0.6, label=\"All\")\nplt.hist(stars_with, bins=40, alpha=0.6, label=\"With photos\")\nplt.hist(stars_without, bins=40, alpha=0.6, label=\"Without photos\")\nplt.xlabel(\"Stars (stars_target)\")\nplt.ylabel(\"Count\")\nplt.title(\"Stars distribution by photo presence\")\nplt.legend()\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Stars vs photo_count / review_count"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "plt.figure()\nplt.scatter(df[\"photo_count\"].to_numpy() + 1, df[\"stars_target\"].to_numpy(), s=6, alpha=0.3)\nplt.xscale(\"log\")\nplt.xlabel(\"photo_count + 1 (log scale)\")\nplt.ylabel(\"stars_target\")\nplt.title(\"Stars vs photo_count\")\nplt.show()\n\nplt.figure()\nplt.scatter(df[\"reviews_n\"].to_numpy() + 1, df[\"stars_target\"].to_numpy(), s=6, alpha=0.3)\nplt.xscale(\"log\")\nplt.xlabel(\"reviews_n + 1 (log scale)\")\nplt.ylabel(\"stars_target\")\nplt.title(\"Stars vs number of reviews\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## If you have predictions, join and analyze error vs coverage"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not PRED_CSV.exists():\n    print(f\"Predictions CSV not found: {PRED_CSV}. Run plot_predictions first.\")\nelse:\n    merged = B.merge_with_predictions(df, PRED_CSV)\n    merged.shape, merged.head()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Abs error vs photo_count / reviews_n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if PRED_CSV.exists():\n    plt.figure()\n    plt.scatter(merged[\"photo_count\"].fill_null(0).to_numpy() + 1, merged[\"abs_error\"].to_numpy(), s=8, alpha=0.4)\n    plt.xscale(\"log\")\n    plt.xlabel(\"photo_count + 1 (log scale)\")\n    plt.ylabel(\"abs_error\")\n    plt.title(\"Abs error vs photo_count\")\n    plt.show()\n\n    plt.figure()\n    plt.scatter(merged[\"reviews_n\"].fill_null(0).to_numpy() + 1, merged[\"abs_error\"].to_numpy(), s=8, alpha=0.4)\n    plt.xscale(\"log\")\n    plt.xlabel(\"reviews_n + 1 (log scale)\")\n    plt.ylabel(\"abs_error\")\n    plt.title(\"Abs error vs number of reviews\")\n    plt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### MAE by buckets (photo_count and reviews_n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if PRED_CSV.exists():\n    photo_edges = B.parse_edges(\"0,1,2,3,5,10,20,50,100,1000000\")\n    review_edges = B.parse_edges(\"0,1,5,10,20,50,100,200,500,1000,1000000\")\n\n    # Save CSVs (script-compatible)\n    B.mae_by_bucket(OUTDIR / \"mae_by_photo_bucket.csv\", merged, col=\"photo_count\", edges=photo_edges, bucket_name=\"photo_bucket\")\n    B.mae_by_bucket(OUTDIR / \"mae_by_review_bucket.csv\", merged, col=\"reviews_n\", edges=review_edges, bucket_name=\"review_bucket\")\n\n    # Display inline\n    print(pl.read_csv(OUTDIR / \"mae_by_photo_bucket.csv\"))\n    print(pl.read_csv(OUTDIR / \"mae_by_review_bucket.csv\"))\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}